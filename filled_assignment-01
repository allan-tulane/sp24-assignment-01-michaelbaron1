

# CMPS 2200 Assignment 1

**Name:**Michael Baron


In this assignment, you will learn more about asymptotic notation, parallelism, functional languages, and algorithmic cost models. As in the recitation, some of your answer will go here and some will go in `main.py`. You are welcome to edit this `assignment-01.md` file directly, or print and fill in by hand. If you do the latter, please scan to a file `assignment-01.pdf` and push to your github repository. 
  
  

1. (2 pts ea) **Asymptotic notation** (12 pts)

  - 1a. Is $2^{n+1} \in O(2^n)$? Why or why not? 
.  Yes. 2^(n+1) = 2 * 2^n, meaning for c >=2 2^(n+1) <= c * 2^(n+1)
.  
.  
.  
. 
  - 1b. Is $2^{2^n} \in O(2^n)$? Why or why not?     
.  no. if you take the log_2 for each it would be 2^(2^n) turn into 2^n and 2^n would = n
  - since 2^n grows at the faster rate exponentially to n, there is no c where 2^(2^n) =< c * 2^n for all n > n0
.  
.  
.  
.  
  - 1c. Is $n^{1.01} \in O(\mathrm{log}^2 n)$?    
.  no. log base n growth slows down faster than an exponent, uncluding 2, could make up for
  - this means that n^1.01, which grows polynomial, is >= c * log^2 n
.  
.  

  - 1d. Is $n^{1.01} \in \Omega(\mathrm{log}^2 n)$?  
.  
..   Yes, for the same reason that the exponent will grow larger with n growing than log does

.  
.  
  - 1e. Is $\sqrt{n} \in O((\mathrm{log} n)^3)$?  
.  
. No becasue while n^1/2 grows slower than linear, it is still growing at a polynomial rate
  - logaritmic rates slow in their growth exponentially, and there is no c that can make
  - logn^3 grow faster for all n>=n0. at any point where there is a c to make logn^3 faster than n^1/2
  - there is a higher value n that will increase faster to logn^3 at the same c
.  
.  
  - 1f. Is $\sqrt{n} \in \Omega((\mathrm{log} n)^3)$?  
.  
Yes, for the same reasons as before, but opposite. polynomial growth is faster than log and therefor it is >. it works for this one since omega is the lower bounds

2. **SPARC to Python** (12 pts)

Consider the following SPARC code of the Fibonacci sequence, which is the series of numbers where each number is the sum of the two preceding numbers. For example, 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610 ... 
$$
\begin{array}{l}
\mathit{foo}~x =   \\
~~~~\texttt{if}{}~~x \le 1~~\texttt{then}{}\\
~~~~~~~~x\\   
~~~~\texttt{else}\\
~~~~~~~~\texttt{let}{}~~(ra, rb) = (\mathit{foo}~(x-1))~~,~~(\mathit{foo}~(x-2))~~\texttt{in}{}\\  
~~~~~~~~~~~~ra + rb\\  
~~~~~~~~\texttt{end}{}.\\
\end{array}
$$ 

  - 2a. (6 pts) Translate this to Python code -- fill in the `def foo` method in `main.py`  

  - 2b. (6 pts) What does this function do, in your own words?  

.  this function get the Xth number of the fibanacii sequence by recursively summing up the previous two until reaching base cases f(0) = = and f(1) = 1. 
.  
.  
.  
.  
.  
.  
.  
  

3. **Parallelism and recursion** (26 pts)

Consider the following function:  

```python
def longest_run(myarray, key)
   """
    Input:
      `myarray`: a list of ints
      `key`: an int
    Return:
      the longest continuous sequence of `key` in `myarray`
   """
```
E.g., `longest_run([2,12,12,8,12,12,12,0,12,1], 12) == 3`  
 
  - 3a. (7 pts) First, implement an iterative, sequential version of `longest_run` in `main.py`.  

  - 3b. (4 pts) What is the Work and Span of this implementation?  

.  
.  this iterative and sequential version of longest_run, which cannot run in parralel, has span and work of O(n)
.  
.  
.  
.  
.  
.  
.  


  - 3c. (7 pts) Next, implement a `longest_run_recursive`, a recursive, divide and conquer implementation. This is analogous to our implementation of `sum_list_recursive`. To do so, you will need to think about how to combine partial solutions from each recursive call. Make use of the provided class `Result`.   

  - 3d. (4 pts) What is the Work and Span of this sequential algorithm?  
.  
.  The work is 2 * W(m/2) + O(1) which = O(n)
.  The span for this is O(logn) as S(n) = S(n/2) + O(1) and using the master thereom for span can be simplified into S(n) = O(logn)
.  it will split up k times for s(n/2) to reach base case where s(n/2^k), resulting in a span of o(logn). this is in the case of parralism. in one were there is no ability to run in parrall, it would remain o(n)
.  
.  
.  


  - 3e. (4 pts) Assume that we parallelize in a similar way we did with `sum_list_recursive`. That is, each recursive call spawns a new thread. What is the Work and Span of this algorithm?  

.  
.  The work equation is O(n) would be W(n) = a * (n/b) + O(n) where work would simplify to O(n)
.  Span here would be O(logn). each step will recursively run till n/2^k reaches base case, so 2^k = n, and k = log_2 n. this is log(n) since it would be ran k times and k*o(1) would sum for span. 
.  
.  
.  
.  
.  

